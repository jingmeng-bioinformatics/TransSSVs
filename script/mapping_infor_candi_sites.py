#!/usr/bin/env python

'''Create a file with mapping information for candidate or validated somatic small variant sites and their neighbours.
'''

import argparse
import re
import itertools
import time
from xphyle import xopen
import numpy as np
import os

parser = argparse.ArgumentParser()

parser.add_argument('--Candidate_validated_somatic_sites', required=True, metavar='file', help='a file of candidate or validated somatic sites')
parser.add_argument('--Tumor_Normal_mpileup', required=True, metavar='pileup', help='a mixed mpileup file from tumor and normal bam files generated by samtools')
parser.add_argument('--indicator', default='inference', metavar='training or inference', help='creating input for the CNN model for training or inference')
parser.add_argument('--number_of_columns', required=True, type=int, help='the number of flanking genomic sites to the left or right of the candidate somatic site')
parser.add_argument('--path', required=True, metavar='DIR', help='path')
parser.add_argument('--filename_1', required=True, metavar='filename_1', help='file_name_1')

args = parser.parse_args()


def find_indel(pattern, source):
    # find all the lengths of inserted or deleted sequences 
    indel = re.findall(pattern, source)
    if len(indel) == 0:
        return [], 0, [], 0, 0  # no indels found
    else:
        indel_new = [int(x[1:]) for x in indel]
        length_of_indel = max(indel_new, key = indel_new.count)  # the length of inserted or deleted bases
        
        if pattern[1] == '+':
            indel_forward = re.findall('\+' + str(length_of_indel) + '(' + '[ACGTN]' + '{' + str(length_of_indel) + '}' + ')', source)
        else:
            indel_forward = re.findall('\-' + str(length_of_indel) + '(' + '[ACGTN]' + '{' + str(length_of_indel) + '}' + ')', source)
        
        # the length of indels in forward strand
        indel_forward_count = len(indel_forward) 
        # the occurences of indels with such length
        indel_count = indel_new.count(length_of_indel) 
        return indel_new, length_of_indel, indel_forward, indel_forward_count, indel_count 

def locate(source, pattern = ['\+[0-9]+', '\-[0-9]+']):
    # identify the indexes and strand information of all the indels and mismatches in the mapped reads in tumor and normal

    # identify all the indels

    
    ###################
    # get the variant 
    allele_insertion_tumor_new, length_of_inserted_bases, inserted_bases_forward, insertion_forward_count, insertion_count = find_indel('\+[0-9]+', source)
    allele_deletion_tumor_new, length_of_deleted_bases, deleted_bases_forward, deletion_forward_count, deletion_count = find_indel('\-[0-9]+', source)

    # replace indels of pattern '-[0-9]+[ACGTNacgtn]+' or '\+[0-9]+[ACGTNacgtn]+' with X
    if allele_insertion_tumor_new == [] and allele_deletion_tumor_new != []:
        allele_deletion_tumor_set = list(set(allele_deletion_tumor_new))
        field_holder = source
        
        # replace deletions in mapped reads in tumor
        for number_deletion in allele_deletion_tumor_set:
            create_pattern = '\-' + str(number_deletion) + '[ACGTNacgtn]' + '{' + str(number_deletion) + '}'
            field_holder = re.sub(create_pattern, 'x', field_holder)

    elif allele_deletion_tumor_new == [] and allele_insertion_tumor_new != []:
        allele_insertion_tumor_set = list(set(allele_insertion_tumor_new))
        field_holder = source
        
        # replace insertions in mapped reads in tumor
        for number in allele_insertion_tumor_set:
            create_pattern = '\+' + str(number) + '[ACGTNacgtn]' + '{' + str(number) + '}'
            field_holder = re.sub(create_pattern, 'x', field_holder)

    elif allele_insertion_tumor_new == [] and allele_deletion_tumor_new == []:
        field_holder = source  # no indels found in mapped reads in tumor

    else:
        # both insertions and deletions found in mapped reads in tumor
        allele_insertion_tumor_set = list(set(allele_insertion_tumor_new))
        allele_deletion_tumor_set = list(set(allele_deletion_tumor_new))
        field_holder = source
        
        for number in allele_insertion_tumor_set:
            create_pattern = '\+' + str(number) + '[ACGTNacgtn]' + '{' + str(number) + '}'
            field_holder = re.sub(create_pattern, 'x', field_holder)
        
        for number_deletion in allele_deletion_tumor_set:
            create_pattern = '\-' + str(number_deletion) + '[ACGTNacgtn]' + '{' + str(number_deletion) + '}'
            field_holder = re.sub(create_pattern, 'x', field_holder)

    # the number of non-reference bases in mapped reads in tumor
    allele_mismatch_count_iter = iter([len(re.findall(base, field_holder)) for base in 'AaTtGgCcNn'])
    allele_forward_count = []
    allele_count = []

    # create a list with the occurences of mismatches in mapped reads in tumor
    for number in allele_mismatch_count_iter:
        allele_forward_count.append(number)   # the occurences of mismatches in the forward strand
        allele_count.append(number + next(itertools.islice(allele_mismatch_count_iter, 0, 1))) # the occurences of mismatches in total

    # a list with the occurences of mismatches and indels
    allele_count.extend([insertion_count, deletion_count])
    allele_forward_count.extend([insertion_forward_count, deletion_forward_count])

    # a list of non-reference allele types
    if allele_insertion_tumor_new == [] and allele_deletion_tumor_new != []:
        if deletion_forward_count == 0:
            allele_types_total = ['A', 'T', 'G', 'C', 'N', '', ''] # no deletion found in the forward strand
        else:
            # add the information about the deletion
            allele_types_total = ['A', 'T', 'G', 'C', 'N', '', '-' + str(length_of_deleted_bases) + str(deleted_bases_forward[0])]

    elif allele_deletion_tumor_new == [] and allele_insertion_tumor_new != []:
        if insertion_forward_count == 0:
            allele_types_total = ['A', 'T', 'G', 'C', 'N', '', '']     # no insertion found in the forward strand
        else:
            # add the information about the insertion 
            allele_types_total = ['A', 'T', 'G', 'C', 'N', '+' + str(length_of_inserted_bases) + str(inserted_bases_forward[0]), '']

    elif allele_insertion_tumor_new == [] and allele_deletion_tumor_new == []:
        allele_types_total = ['A', 'T', 'G', 'C', 'N', '', '']  # no indels found

    else:
        if insertion_forward_count == 0 and deletion_forward_count == 0:
            allele_types_total = ['A', 'T', 'G', 'C', 'N', '', '']
        elif insertion_forward_count != 0 and deletion_forward_count == 0:
            # add the information about the insertion in the forward strand
            allele_types_total = ['A', 'T', 'G', 'C', 'N', '+' + str(length_of_inserted_bases) + str(inserted_bases_forward[0]), '']
        elif insertion_forward_count == 0 and deletion_forward_count != 0:
            # add the information about the deletion in the forward strand
            allele_types_total = ['A', 'T', 'G', 'C', 'N', '', '-' + str(length_of_deleted_bases) + str(deleted_bases_forward[0])]
        else:
            allele_types_total = ['A', 'T', 'G', 'C', 'N', '+' + str(length_of_inserted_bases) + str(inserted_bases_forward[0]), '-' + str(length_of_deleted_bases) + str(deleted_bases_forward[0])]

    # the potential allele type
    max_index = allele_count.index(max(allele_count))
    
    ########
    
    

    
    
    
    field_holder = source
    k_dict={}
    k_dict['1']=[]
    k_dict['0']=[]
    k_dict['0.25']=[]
    k_dict['0.75']=[]
    k_dict['0.5']=[]
    k_dict['0.025']=[]
    k_dict['0.075']=[]
    k_dict['0.05']=[]
    # remove the symbol that marks the start or end of a read segment
    field_holder = re.sub('\$', '', field_holder)
    field_holder = re.sub('\^.', '', field_holder)
    index_all = []
    strand_all = []
    state_all = []




    if max(allele_count)== 0:
        pass
    else:
        if 0.1 <= (allele_forward_count[max_index]/max(allele_count)) <= 0.90:
            if allele_types_total[max_index].upper()[0]=='+'or allele_types_total[max_index].upper()[0]=='-':
                marked_allele_upper= '\\'+ str(allele_types_total[max_index].upper()) # marked allele
                marked_allele_lower= '\\'+ str(allele_types_total[max_index].lower()) # marked allele
                if allele_types_total[max_index].upper()[0]=='+':
                    field_holder=re.sub('\.'+marked_allele_upper, 'I', field_holder)
                    field_holder=re.sub(','+marked_allele_lower, 'i', field_holder)
                else:
                    field_holder=re.sub('\.'+marked_allele_upper, 'D', field_holder)
                    field_holder=re.sub(','+marked_allele_lower, 'd', field_holder)
            else:
                pass
        else:
            pass

    
    

    # identify all the indels
    mask = re.findall('[\+\-][0-9]+', field_holder)
    mask_new = [int(x[1:]) for x in mask]
    for patt in pattern:
        match = re.findall(patt, field_holder)

        # identify the insertion
        if patt[1] == '+' and len(match) > 0:
            match_new = [int(x[1:]) for x in match]
            match_set = sorted(list(set(match_new)))
            for num in match_set:
                # identify the insertion in the forward strand
                create_pattern = '\+' + str(num) + '[ACGTN]' + '{' + str(num) + '}'
                field_holder = re.sub(create_pattern, 'X', field_holder)
                
                # remove other indels
                tem_holder = field_holder
                for tem in sorted(list(set(mask_new) - set([num]))):
                    create_tem_pattern = '\+' + str(tem) + '[ACGTNacgtn]' + '{' + str(tem) + '}'
                    tem_holder = re.sub(create_tem_pattern, '', tem_holder)
                    create_tem_pattern = '\-' + str(tem) + '[ACGTNacgtn]' + '{' + str(tem) + '}'
                    tem_holder = re.sub(create_tem_pattern, '', tem_holder)
                create_tem_pattern = '\+' + str(num) + '[acgtn]' + '{' + str(num) + '}'
                tem_holder = re.sub(create_tem_pattern, '', tem_holder)
                create_tem_pattern = '\-' + str(num) + '[ACGTNacgtn]' + '{' + str(num) + '}'
                tem_holder = re.sub(create_tem_pattern, '', tem_holder)

                # identify the indexes of the specific insertion in the forward strand in the processed mapped reads
                position = [m.start() for m in re.finditer('X', tem_holder)]
                if len(position) == 0:
                    pass
                else:
                    for i in position:
                        index_all.append(i - position.index(i) - 1)
                        strand_all.append('1') # forward strand
                        state_all.append('0.025') # insertion
                        k_dict['0.025'].append(i - position.index(i) - 1)
                field_holder = re.sub('X', '', field_holder)
                
                # identify the insertion in the reverse strand
                create_pattern = '\+' + str(num) + '[acgtn]' + '{' + str(num) + '}'
                field_holder = re.sub(create_pattern, 'x', field_holder)
                
                # remove other indels
                tem_holder = field_holder
                for tem in sorted(list(set(mask_new) - set([num]))):
                    create_tem_pattern = '\+' + str(tem) + '[ACGTNacgtn]' + '{' + str(tem) + '}'
                    tem_holder = re.sub(create_tem_pattern, '', tem_holder)
                    create_tem_pattern = '\-' + str(tem) + '[ACGTNacgtn]' + '{' + str(tem) + '}'
                    tem_holder = re.sub(create_tem_pattern, '', tem_holder)
                create_tem_pattern = '\+' + str(num) + '[ACGTN]' + '{' + str(num) + '}'
                tem_holder = re.sub(create_tem_pattern, '', tem_holder)
                create_tem_pattern = '\-' + str(num) + '[ACGTNacgtn]' + '{' + str(num) + '}'
                tem_holder = re.sub(create_tem_pattern, '', tem_holder)
                
                # identify the indexes of the specific insertion in the reverse strand
                position = [m.start() for m in re.finditer('x', tem_holder)]
                if len(position) == 0:
                    pass
                else:
                    for i in position:
                        index_all.append(i - position.index(i) - 1)
                        strand_all.append('0.5') # reverse strand
                        state_all.append('0.025') # insertion
                        k_dict['0.025'].append(i - position.index(i) - 1)
                field_holder = re.sub('x', '', field_holder)
        
        # no indels found
        elif patt[1] == '+' and len(match) == 0:
            pass
        elif patt[1] == '-' and len(match) == 0:
            pass

        # identify the deletion
        elif patt[1] == '-' and len(match) > 0:
            match_new = [int(x[1:]) for x in match]
            match_set = sorted(list(set(match_new)))
            for num in match_set:
                # identify the deletion in the forward strand
                create_pattern = '\-' + str(num) + '[ACGTN]' + '{' + str(num) + '}'
                field_holder = re.sub(create_pattern, 'X', field_holder)
                
                # remove other indels
                tem_holder = field_holder
                for tem in sorted(list(set(mask_new) - set([num]))):
                    create_tem_pattern = '\+' + str(tem) + '[ACGTNacgtn]' + '{' + str(tem) + '}'
                    tem_holder = re.sub(create_tem_pattern, '', tem_holder)
                    create_tem_pattern = '\-' + str(tem) + '[ACGTNacgtn]' + '{' + str(tem) + '}'
                    tem_holder = re.sub(create_tem_pattern, '', tem_holder)
                create_tem_pattern = '\+' + str(num) + '[ACGTNacgtn]' + '{' + str(num) + '}'
                tem_holder = re.sub(create_tem_pattern, '', tem_holder)
                create_tem_pattern = '\-' + str(num) + '[acgtn]' + '{' + str(num) + '}'
                tem_holder = re.sub(create_tem_pattern, '', tem_holder)
                
                # identify the indexes of the specific deletion in the forward strand
                position = [m.start() for m in re.finditer('X', tem_holder)]
                if len(position) == 0:
                    pass
                else:
                    for i in position:
                        index_all.append(i - position.index(i) - 1)
                        strand_all.append('1') # forward strand
                        state_all.append('0.05') # deletion
                        k_dict['0.05'].append(i - position.index(i) - 1)
                field_holder = re.sub('X', '', field_holder)
                
                # identify the deletion in the reverse strand
                create_pattern = '\-' + str(num) + '[acgtn]' + '{' + str(num) + '}'
                field_holder = re.sub(create_pattern, 'x', field_holder)
                
                # remove other indels
                tem_holder = field_holder
                for tem in sorted(list(set(mask_new) - set([num]))):
                    create_tem_pattern = '\+' + str(tem) + '[ACGTNacgtn]' + '{' + str(tem) + '}'
                    tem_holder = re.sub(create_tem_pattern, '', tem_holder)
                    create_tem_pattern = '\-' + str(tem) + '[ACGTNacgtn]' + '{' + str(tem) + '}'
                    tem_holder = re.sub(create_tem_pattern, '', tem_holder)
                create_tem_pattern = '\+' + str(num) + '[ACGTNacgtn]' + '{' + str(num) + '}'
                tem_holder = re.sub(create_tem_pattern, '', tem_holder)
                create_tem_pattern = '\-' + str(num) + '[ACGTN]' + '{' + str(num) + '}'
                tem_holder = re.sub(create_tem_pattern, '', tem_holder)
                
                # identify the indexes of the specific deletion in the reverse strand
                position = [m.start() for m in re.finditer('x', tem_holder)]
                if len(position) == 0:
                    pass
                else:
                    for i in position:
                        index_all.append(i - position.index(i) - 1)
                        strand_all.append('0.5') # reverse strand
                        state_all.append('0.05') # deletion
                        k_dict['0.05'].append(i - position.index(i) - 1)
                field_holder = re.sub('x', '', field_holder)
    indel_index = index_all


    if max(allele_count)== 0:
        pass
    else:
        if 0.1 <= (allele_forward_count[max_index]/max(allele_count)) <= 0.90:
            if allele_types_total[max_index].upper()[0]=='+'or allele_types_total[max_index].upper()[0]=='-':
                pass
            else:
                marked_allele_upper=str(allele_types_total[max_index].upper())
                marked_allele_lower=str(allele_types_total[max_index].lower()) 
                field_holder=re.sub(marked_allele_upper, 'M', field_holder)
                field_holder=re.sub(marked_allele_lower, 'm', field_holder)
        else:
            pass


    # identify the indexes of mismatched and matched bases
    for base in ['A', 'a', 'T', 't', 'G', 'g', 'C', 'c', 'N', 'n', '\.', ',','I','i','D','d','M','m']:
        if len(re.findall(base, field_holder)) == 0:
            pass        # no mismatched and matched bases found
        else:
            position = [m.start() for m in re.finditer(base, field_holder)]

            # check if there are indexes of matched bases followed by indels
            if len(indel_index) == 0:
                for i in position:
                    index_all.append(i)
                    if base in 'AaTtGgCcNnIiDdMm':
                        if base in 'Nn':
                            state_all.append('0') # mismatch-Nn
                            k_dict['0'].append(i)
                        elif base in 'Ii':
                            state_all.append('0.25') # insert
                            k_dict['0.25'].append(i)
                        elif base in 'Dd':
                            state_all.append('0.5') # insert
                            k_dict['0.5'].append(i)
                        elif base in 'Mm':
                            state_all.append('0.75') # mismatch
                            k_dict['0.75'].append(i)
                        else:
                            state_all.append('0.075') # mismatch
                            k_dict['0.075'].append(i)
                        if base.isupper():
                            strand_all.append('1') # forward strand
                        else:
                            strand_all.append('0.5') # reverse strand
                    else:
                        state_all.append('1') # match
                        k_dict['1'].append(i)
                        if base == '\.':
                            strand_all.append('1') # forward strand
                        else:
                            strand_all.append('0.5') # reverse strand
            else: 
                # keep just the indexes of mismatches or matches
                position = sorted(list(set(position) - set(indel_index)))  
                for i in position:
                    index_all.append(i)
                    if base in 'AaTtGgCcNnIiDdMm':
                        if base in 'Nn':
                            state_all.append('0') # mismatch-Nn
                            k_dict['0'].append(i)
                        elif base in 'Ii':
                            state_all.append('0.25') # insert
                            k_dict['0.25'].append(i)
                        elif base in 'Dd':
                            state_all.append('0.5') # insert
                            k_dict['0.5'].append(i)
                        elif base in 'Mm':
                            state_all.append('0.75') # mismatch
                            k_dict['0.75'].append(i)
                        else:
                            state_all.append('0.075') # mismatch
                            k_dict['0.075'].append(i)
                        if base.isupper():
                            strand_all.append('1') # forward strand
                        else:
                            strand_all.append('0.5') # reverse strand
                    else:
                        state_all.append('1') # match
                        k_dict['1'].append(i)
                        if base == '\.':
                            strand_all.append('1') # forward strand
                        else:
                            strand_all.append('0.5') # reverse strand
    

    return index_all, strand_all, state_all, field_holder, k_dict



def append_mapping_infor(index_list, strand_all_list, state_all_list, field_holder_sample, mapping, sample):
    '''
    base = ['A', 'T', 'G', 'C', 'N']
    encoding = ['00001', '00010', '00100', '01000', '10000'] # encoding for bases
    '''
    mq_list=[]
    bq_list=[]
    dis_list=[]
    for i in index_list:
        # encoding base, mapping quality and distance to the read end in normal
        if sample == 'normal':
            bq = mapping[10][i]
            prob_bq=ord(bq)
            bq_list.append(prob_bq)   # base quality
            mq = mapping[11][i]
            prob_mq=ord(mq)
            mq_list.append(prob_mq)  # mapping quality

        
        # encoding base, mapping quality and distance to the read end in tumor
        else:
            bq = mapping[5][i]
            prob_bq=ord(bq)

            bq_list.append(prob_bq)   # base quality
            mq = mapping[6][i]
            prob_mq=ord(mq)

            mq_list.append(prob_mq)  # mapping quality

    return mq_list, bq_list # mapping information in one genomic site or column


def get_matrix_1(index_all, strand_all, state_all,mq_list,bq_list,k_dict):
    matrix=np.zeros((1,26),dtype='float32')
    list_k=[len(k_dict['0.25']),len(k_dict['0.5']),len(k_dict['0.75'])]
    list_k_index=['0.25','0.5','0.75']
    k=list_k.index(max(list_k))
    variant_allele=k_dict[list_k_index[k]]
    ref_allele=k_dict['1']

    mq_list_variant=[]
    bq_list_variant=[]
    for i in variant_allele:
        j = index_all.index(i)
        mq_list_variant.append(mq_list[j])
        bq_list_variant.append(bq_list[j])

    mq_list_ref=[]
    bq_list_ref=[]
    for i in ref_allele:
        j = index_all.index(i)
        mq_list_ref.append(mq_list[j])
        bq_list_ref.append(bq_list[j])


    mq_mean_ref=0 if len(mq_list_ref)==0 else np.mean(mq_list_ref)
    mq_mean_variant=0 if len(mq_list_variant)==0 else np.mean(mq_list_variant)
    bq_mean_ref=0 if len(bq_list_ref)==0 else np.mean(bq_list_ref)
    bq_mean_variant=0 if len(bq_list_variant)==0 else np.mean(bq_list_variant)
    bq_mid_ref=[0,0,0] if len(bq_list_ref)==0 else np.percentile(bq_list_ref,(25,50,75),interpolation='midpoint')
    bq_mid_variant=[0,0,0] if len(bq_list_variant)==0 else np.percentile(bq_list_variant,(25,50,75),interpolation='midpoint')
    mq_mid_ref=[0,0,0] if len(mq_list_ref)==0 else np.percentile(mq_list_ref,(25,50,75),interpolation='midpoint')
    mq_mid_variant=[0,0,0] if len(mq_list_variant)==0 else np.percentile(mq_list_variant,(25,50,75),interpolation='midpoint')
    bq_max_ref=0 if len(bq_list_ref)==0 else max(bq_list_ref)
    bq_min_ref=0 if len(bq_list_ref)==0 else min(bq_list_ref)
    mq_max_ref=0 if len(mq_list_ref)==0 else max(mq_list_ref)
    mq_min_ref=0 if len(mq_list_ref)==0 else min(mq_list_ref)
    
    bq_max_variant=0 if len(bq_list_variant)==0 else max(bq_list_variant)
    bq_min_variant=0 if len(bq_list_variant)==0 else min(bq_list_variant)
    mq_max_variant=0 if len(mq_list_variant)==0 else max(mq_list_variant)
    mq_min_variant=0 if len(mq_list_variant)==0 else min(mq_list_variant)

    total=len(variant_allele) + len(ref_allele)
    vaf_ref=0 if total==0 else (len(ref_allele)/total)
    vaf_varant=0 if total==0 else (len(variant_allele)/total)

    matrix[0,0]=len(ref_allele)
    matrix[0,1]=len(variant_allele)
    matrix[0,2]=mq_mean_ref
    matrix[0,3]=mq_mean_variant
    matrix[0,4]=bq_mean_ref
    matrix[0,5]=bq_mean_variant
    matrix[0,6]=mq_mid_ref[0]
    matrix[0,7]=mq_mid_variant[0]
    matrix[0,8]=mq_mid_ref[1]
    matrix[0,9]=mq_mid_variant[1]
    matrix[0,10]=mq_mid_ref[2]
    matrix[0,11]=mq_mid_variant[2]
    matrix[0,12]=bq_mid_ref[0]
    matrix[0,13]=bq_mid_variant[0]
    matrix[0,14]=bq_mid_ref[1]
    matrix[0,15]=bq_mid_variant[1]
    matrix[0,16]=bq_mid_ref[2]
    matrix[0,17]=bq_mid_variant[2]
    matrix[0,18]=mq_max_ref
    matrix[0,19]=mq_max_variant
    matrix[0,20]=mq_min_ref
    matrix[0,21]=mq_min_variant
    matrix[0,22]=bq_max_ref
    matrix[0,23]=bq_max_variant
    matrix[0,24]=bq_min_ref
    matrix[0,25]=bq_min_variant


    return matrix


def generate_mapping_infor_reads(col):
    #base = ['A', 'T', 'G', 'C', 'N']
    #encoding = ['00001', '00010', '00100', '01000', '10000'] # encoding for bases
    lines = []
    mapping = col[1].rstrip('\n').split('\t')
    
    # the first 5 rows: encoding for base in the reference genome
    
    
    #for ele in encoding[base.index(mapping[2].upper())]:
        #lines.append(ele)    
    
    
    # max(depth) = 100 
    # each read base takes 5 rows ( strand: 1 rows, state: 1 rows, base_quality: 1 row, mapping quality: 1 row and distance: 1 row)
    # the number of total rows in each column is 1000 (100*5 + 100*5)
    index_all_tumor, strand_all_tumor, state_all_tumor, field_holder_tumor, dict_all_tumor = locate(mapping[4])
    index_all_normal, strand_all_normal, state_all_normal, field_holder_normal ,dict_all_normal= locate(mapping[9])
    mq_list_tumor, bq_list_tumor = append_mapping_infor(index_all_tumor, strand_all_tumor, state_all_tumor, field_holder_tumor, mapping, 'tumor')
    mq_list_normal, bq_list_normal = append_mapping_infor(index_all_normal, strand_all_normal, state_all_normal, field_holder_normal, mapping, 'normal')

    matrix_1_tumor=get_matrix_1(index_all_tumor, strand_all_tumor, state_all_tumor,mq_list_tumor,bq_list_tumor,dict_all_tumor)
    matrix_1_normal=get_matrix_1(index_all_normal,strand_all_normal,state_all_normal,mq_list_normal,bq_list_normal,dict_all_normal)
    
    matrix_1=np.zeros((1,52),dtype='float32')
    matrix_1[0,0:26]=matrix_1_normal
    matrix_1[0,26:52]=matrix_1_tumor

    return matrix_1

def main(args):
    with xopen(args.Tumor_Normal_mpileup, 'rt') as TN, open(args.Candidate_validated_somatic_sites, 'rt') as Cs:
        enume_Cs = enumerate(Cs) 
        enume_TN = enumerate(TN)
        os.mkdir(args.path+'/'+args.filename_1+'_npyarray/')
        i=0
        j=1
        shape_y=int((args.number_of_columns)*2+1)
        npyarray_1=np.zeros((shape_y,52,0),dtype='float32')
        if args.indicator == 'training':
            label_array=np.zeros((0),dtype='int64')
        else:
            pass
        for line in enume_Cs:
            holder = []
            # creating input for training or inference
            if args.indicator == 'training':
                label = []
            else:
                pass

            #base = ['A', 'T', 'G', 'C', 'N']
            line_content = line[1].rstrip('\n').split('\t')
            
            # encoding for bases
            #encoding = ['00001', '00010', '00100', '01000', '10000'] 
            
            matrix_1_all=np.zeros((0,52),dtype='float32')
            
            
            # process the first line

            if line[0] == 0:
                for col in itertools.islice(enume_TN, int(line_content[0]) - args.number_of_columns, int(line_content[0]) + args.number_of_columns +1):
                    matrix_1 = generate_mapping_infor_reads(col)
                    matrix_1_all=np.concatenate((matrix_1_all,matrix_1))
                    
                keep = int(line_content[0])

                # creating input for training or inference
                if args.indicator == 'training':

                    label.append(line_content[3])

                    overlap_1 = matrix_1_all
                else:
                    overlap_1 = matrix_1_all

            else: 
                # the distance between two candidate or validated genomic sites 
                gap = int(line_content[0]) - keep
                
                # the distance larger than the window size of 2*n
                if gap > 2*args.number_of_columns:
                    for col in itertools.islice(enume_TN, gap - 2*args.number_of_columns -1, gap):
                        matrix_1 = generate_mapping_infor_reads(col)
                        matrix_1_all=np.concatenate((matrix_1_all,matrix_1))

                    # creating input for training or inference
                    if args.indicator == 'training':

                        label.append(line_content[3])

                        overlap_1 = matrix_1_all
                    else:
                        overlap_1 = matrix_1_all
                    keep = int(line_content[0])

                else:
                    # copy the information of overlapping window from last column
                    matrix_1_all=np.concatenate((matrix_1_all,overlap_1[gap:,:]))

                    overlap = []
                    for col in itertools.islice(enume_TN, 0, gap):
                        matrix_1 = generate_mapping_infor_reads(col)
                        matrix_1_all=np.concatenate((matrix_1_all,matrix_1))

                    # creating input for training or inference
                    if args.indicator == 'training':
                        label.append(line_content[3])
                        overlap_1 = matrix_1_all

                    else:
                        overlap_1 = matrix_1_all


                    keep = int(line_content[0])

            matrix_1_all=matrix_1_all.reshape(matrix_1_all.shape[0],matrix_1_all.shape[1],1)
            if args.indicator == 'training':
                label_npy=np.array(label,dtype='int64')
            else:
                pass
                npyarray_1=np.concatenate((npyarray_1,matrix_1_all),axis=2)
        npyarray_1=npyarray_1.transpose(2,0,1)
        if args.indicator == 'training':
            np.save(args.path+'/'+args.filename_1+'_npyarray/'+'data.'+args.filename_1+str(j)+'.npy',npyarray_1)
            np.save(args.path+'/'+args.filename_1+'_npyarray/'+'label.'+args.filename_1+str(j)+'.npy',label_array)

        else:
            pass
        np.save(args.path+'/'+args.filename_1+'_npyarray/'+'data.'+args.filename_1+'.npy',npyarray_1)



if __name__ == '__main__':
    start_time = time.time()
    main(args)
    print('--- %s seconds ---' %(time.time() - start_time))